{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_434_Deploy_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "nteract": {
      "version": "0.22.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvanCampos11/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/module4-Deploy/LS_DS_434_Deploy_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NGGrt9EYlCqY"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Train Practice\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
        "\n",
        "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Apply regularization techniques to your model. \n",
        "\n",
        "*Don't forgot to switch to GPU on Colab!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptJ2b3wk62Ud",
        "colab_type": "text"
      },
      "source": [
        "## Regularization\n",
        "\n",
        "Using your best performing model from the previous module, apply each of the following regularization strategies: \n",
        "* Early Stopping\n",
        "* Dropout\n",
        "* Weight Decay\n",
        "* Weight Constraint\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USXjs7Hk71Hy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your Code Starts Here\n",
        "# {'num_units': 32, 'learning_rate': 0.001, 'optimizer': 'adam'}\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxJ2XSk5sCBR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABKl2pUOsS_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_quickdraw10(path):\n",
        "  data = np.load(path)\n",
        "  X = data['arr_0']\n",
        "  y = data['arr_1']\n",
        "  X, y = shuffle(X, y)\n",
        "\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2)\n",
        "\n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXUVrdmpsTCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train, X_test, y_test = load_quickdraw10('quickdraw10.npz')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRr29W_csTEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train = X_train / 255.0\n",
        "# X_test = X_test / 255.0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL84b40osTJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f7c890-3c4e-4da6-fdc1-6a46ab41be96"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.layers import ReLU\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "logdir = os.path.join(\"logs\", \"EarlyStopping-Loss\")\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "stop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    Flatten(),\n",
        "    Dense(512),\n",
        "    ReLU(negative_slope=.01),\n",
        "    Dense(512),\n",
        "    ReLU(negative_slope=.01),\n",
        "    Dense(512),\n",
        "    ReLU(negative_slope=.01),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=99, \n",
        "          validation_data=(X_test,y_test),\n",
        "          callbacks=[tensorboard_callback, stop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/99\n",
            "   1/2500 [..............................] - ETA: 0s - loss: 82.7688 - accuracy: 0.1562WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0078s vs `on_train_batch_end` time: 0.0327s). Check your callbacks.\n",
            "2500/2500 [==============================] - 9s 4ms/step - loss: 1.3554 - accuracy: 0.7563 - val_loss: 0.6166 - val_accuracy: 0.8130\n",
            "Epoch 2/99\n",
            "2491/2500 [============================>.] - ETA: 0s - loss: 0.5580 - accuracy: 0.8308"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co8WbLdlss2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "logdir = os.path.join(\"logs\", \"EarlyStopping+L2_WeightDecay\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "stop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    Flatten(),\n",
        "    Dense(512, kernel_regularizer=regularizers.l2(0.01)),\n",
        "    ReLU(negative_slope=.01),\n",
        "    Dense(512, kernel_regularizer=regularizers.l2(0.01)),\n",
        "    ReLU(negative_slope=.01),\n",
        "    Dense(512, kernel_regularizer=regularizers.l2(0.01)),\n",
        "    ReLU(negative_slope=.01),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=99, \n",
        "          validation_data=(X_test,y_test),\n",
        "          callbacks=[tensorboard_callback, stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCSb2ZI3sTLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu9MLkZJsTPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.constraints import MaxNorm\n",
        "\n",
        "wc = MaxNorm(max_value=2)\n",
        "\n",
        "logdir = os.path.join(\"logs\", \"EarlyStopping+WeightConstraint\")\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "stop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    Flatten(),  \n",
        "    Dense(512, kernel_constraint=wc),\n",
        "    ReLU(negative_slope=.01),\n",
        "    Dense(512, kernel_constraint=wc),\n",
        "    ReLU(negative_slope=.01),\n",
        "    Dense(512, kernel_constraint=wc),\n",
        "    ReLU(negative_slope=.01),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=99, \n",
        "          validation_data=(X_test,y_test),\n",
        "          callbacks=[tensorboard_callback, stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DwwTy_XyfVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "\n",
        "wc = MaxNorm(max_value=2)\n",
        "\n",
        "logdir = os.path.join(\"logs\", \"EarlyStopping+WeightConstraint+Dropout\")\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "stop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    Flatten(),\n",
        "    Dense(512, kernel_constraint=wc),\n",
        "    ReLU(negative_slope=.01),\n",
        "    Dropout(.2),\n",
        "    Dense(512, kernel_constraint=wc),\n",
        "    ReLU(negative_slope=.01),\n",
        "    Dropout(.2),\n",
        "    Dense(512, kernel_constraint=wc),\n",
        "    ReLU(negative_slope=.01),\n",
        "    Dropout(.2),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=99, \n",
        "          validation_data=(X_test,y_test),\n",
        "          callbacks=[tensorboard_callback, stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEiTya9ayfYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pScpa3nRRxCN",
        "colab_type": "text"
      },
      "source": [
        "## Deploy\n",
        "\n",
        "Save your model's weights using the Checkpoint function. Try reloading the model and making inference on your validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cqpHQt_SIbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Your Code Starts Here\n",
        "import tensorflow as tf\n",
        "\n",
        "cpoint = tf.keras.callbacks.ModelCheckpoint(\"weights_best.h5\",\n",
        "                                            verbose=1, \n",
        "                                            save_weights_only=True)\n",
        "\n",
        "def create_model():\n",
        "  model = tf.keras.Sequential([\n",
        "      Flatten(),\n",
        "      Dense(128),\n",
        "      ReLU(negative_slope=.01),\n",
        "      Dense(128),\n",
        "      ReLU(negative_slope=.01),\n",
        "      Dense(128),\n",
        "      ReLU(negative_slope=.01),\n",
        "      Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "model.fit(X_train, y_train, epochs=2, \n",
        "          validation_data=(X_test,y_test),\n",
        "          verbose=2,\n",
        "          callbacks=[cpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKbr1gRg9BXs",
        "colab_type": "text"
      },
      "source": [
        "### Stretch Goals\n",
        "- Mount your Google Drive to Colab to persist your model checkpoint files. \n",
        "- Research L2 normalization (weight decay)\n",
        "- Write a custom callback function to stop training after you reach .88 validation accuracy. \n",
        "- Select a new dataset and apply a neural network to it.\n",
        "- Research TensorFlow Serving\n",
        "- Play [QuickDraw](https://quickdraw.withgoogle.com/data)\n",
        "- Create a static webpage using TensorFlow.js to serve a model. Check out [Teachable Machine Learning](https://teachablemachine.withgoogle.com/) for ideas. "
      ]
    }
  ]
}